---
title: Predicting Taxis Fare in New York City
date: 2018-11-09
tags: 
  - Machine Learning
  - Regression
header:
  image: "/images/NYC Taxi/new york taxi.jpg"
  teaser: "/images/NYC Taxi/new york taxi.jpg"
excerpt: "Machine Learning, Regression"
mathjax: "true"
---

Predicting the fare amount (inclusive of tolls) for a taxi ride in New York City given the pickup and dropoff locations. This dataset is taken from kaggle, [New York City Taxi Fare Prediction](https://www.kaggle.com/c/new-york-city-taxi-fare-prediction).

The features in the dataset are:
* fare_amount — dollar amount of the cost of the taxi ride.
* pickup_datetime — value indicating when the taxi ride started.
* pickup_longitude — longitude coordinate of where the taxi ride started.
* pickup_latitude — latitude coordinate of where the taxi ride started.
* dropoff_longitude — longitude coordinate of where the taxi ride ended.
* dropoff_latitude — latitude coordinate of where the taxi ride ended.
* passenger_count — the number of passengers in the taxi ride.

The target variable will be the fare amount of the taxi ride.

<img src="{{ site.url }}{{ site.baseurl }}/images/NYC Taxi/nyc.png" alt="">

## 1) Setup
### Load packages
```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
```

### Load & Viewing the Data
Using 3 million rows out of the total of 55 million rows in the dataset from kaggle and also dropping the column, key.
```python
pd.set_option('display.float_format', lambda x: '%.3f' % x)
nyc = pd.read_csv("C:/Users/Weasel/Desktop/NYC Taxi/train.csv", nrows = 3_000_000, parse_dates = ['pickup_datetime']).drop(columns = 'key')
nyc.head()
```
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fare_amount</th>
      <th>pickup_datetime</th>
      <th>pickup_longitude</th>
      <th>pickup_latitude</th>
      <th>dropoff_longitude</th>
      <th>dropoff_latitude</th>
      <th>passenger_count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>4.500</td>
      <td>2009-06-15 17:26:21</td>
      <td>-73.844</td>
      <td>40.721</td>
      <td>-73.842</td>
      <td>40.712</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>16.900</td>
      <td>2010-01-05 16:52:16</td>
      <td>-74.016</td>
      <td>40.711</td>
      <td>-73.979</td>
      <td>40.782</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5.700</td>
      <td>2011-08-18 00:35:00</td>
      <td>-73.983</td>
      <td>40.761</td>
      <td>-73.991</td>
      <td>40.751</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>7.700</td>
      <td>2012-04-21 04:30:42</td>
      <td>-73.987</td>
      <td>40.733</td>
      <td>-73.992</td>
      <td>40.758</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.300</td>
      <td>2010-03-09 07:51:00</td>
      <td>-73.968</td>
      <td>40.768</td>
      <td>-73.957</td>
      <td>40.784</td>
      <td>1</td>
    </tr>
  </tbody>
</table>

## 2) Data Preprocessing
### View the types of data in the dataset
```python
nyc.dtypes
```
{% highlight text %}
fare_amount                 float64
pickup_datetime      datetime64[ns]
pickup_longitude            float64
pickup_latitude             float64
dropoff_longitude           float64
dropoff_latitude            float64
passenger_count               int64
dtype: object
{% endhighlight %} 

### Check for missing values in the dataset
```python
nyc.isnull().sum()
```
{% highlight text %}
fare_amount           0
pickup_datetime       0
pickup_longitude      0
pickup_latitude       0
dropoff_longitude    23
dropoff_latitude     23
passenger_count       0
dtype: int64
{% endhighlight %} 
There are 23 missing values in the dropoff longitude and latitude.

### Drop the nan columns
```python
nyc = nyc.dropna()
# Checking missing value
nyc.isnull().sum()
```
{% highlight text %}
fare_amount          0
pickup_datetime      0
pickup_longitude     0
pickup_latitude      0
dropoff_longitude    0
dropoff_latitude     0
passenger_count      0
dtype: int64
{% endhighlight %} 

### Feature Extraction - Haversine distance
Calculating a more realistic distance between the pickup and dropoff location using the [Haversine distance](https://en.wikipedia.org/wiki/Haversine_formula). 
<br/>
$${\text Haversine}= {\text 2r\ arcsin}\left(\sqrt {sin^2\left(\frac{\phi_2 - \phi_1}{2}\right) + cos(\phi_1)cos(\phi_2)sin^2\left(\frac{\lambda_2 - \lambda_1}{2}\right)}\right)$$
<br/>
Where:
* r is the radius of the sphere,
* $$\phi_1$$, $$\phi_2$$ is the latitude of point 1 and latitude of point 2,
* $$\lambda_1$$, $$\lambda_2$$ is the longitude of point 1 and longitude of point 2.
<br/>

The haversine formula determines the great-circle distance representing the shortest distance along the surface of the Earth connecting two points(given their longitudes and latitudes), with assumption that the Earth is a sphere.
<br/>

It's not the best measure because the taxis do not travel along lines, but it's more accurate in terms of an absolute distance than the Manhattan and Euclidean distances, made from the absolute latitude and longitude difference. The Manhattan and Euclidean distances are relative and do not take into account the spherical shape of the Earth.

```python
def haversine(lon1, lat1, lon2, lat2):
    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])

    dlon = lon2 - lon1
    dlat = lat2 - lat1

    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2

    c = 2 * np.arcsin(np.sqrt(a))
    # Earth's average radius is about 6,371 kilometres (3,959 miles).
    km = 6371 * c
    return km
```

### Apply the haversine function and view the dataset
```python
nyc['distance'] = haversine(nyc['pickup_latitude'], nyc['pickup_longitude'], nyc['dropoff_latitude'] , nyc['dropoff_longitude'])
```

### Feature Extraction - Datetime
Extracting the year, month, day, day of the week and hour given the pickup datetime.
```python
nyc['year'] = nyc.pickup_datetime.dt.year
nyc['month'] = nyc.pickup_datetime.dt.month
nyc['day'] = nyc.pickup_datetime.dt.day
nyc['weekday'] = nyc.pickup_datetime.dt.weekday
nyc['hour'] = nyc.pickup_datetime.dt.hour
```

### View the dataset
```python
nyc.head()
```
<div style="overflow-x:auto;">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fare_amount</th>
      <th>pickup_datetime</th>
      <th>pickup_longitude</th>
      <th>pickup_latitude</th>
      <th>dropoff_longitude</th>
      <th>dropoff_latitude</th>
      <th>passenger_count</th>
      <th>distance</th>
      <th>year</th>
      <th>month</th>
      <th>day</th>
      <th>weekday</th>
      <th>hour</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>4.500</td>
      <td>2009-06-15 17:26:21</td>
      <td>-73.844</td>
      <td>40.721</td>
      <td>-73.842</td>
      <td>40.712</td>
      <td>1</td>
      <td>0.410</td>
      <td>2009</td>
      <td>6</td>
      <td>15</td>
      <td>0</td>
      <td>17</td>
    </tr>
    <tr>
      <th>1</th>
      <td>16.900</td>
      <td>2010-01-05 16:52:16</td>
      <td>-74.016</td>
      <td>40.711</td>
      <td>-73.979</td>
      <td>40.782</td>
      <td>1</td>
      <td>4.629</td>
      <td>2010</td>
      <td>1</td>
      <td>5</td>
      <td>1</td>
      <td>16</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5.700</td>
      <td>2011-08-18 00:35:00</td>
      <td>-73.983</td>
      <td>40.761</td>
      <td>-73.991</td>
      <td>40.751</td>
      <td>2</td>
      <td>1.001</td>
      <td>2011</td>
      <td>8</td>
      <td>18</td>
      <td>3</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>7.700</td>
      <td>2012-04-21 04:30:42</td>
      <td>-73.987</td>
      <td>40.733</td>
      <td>-73.992</td>
      <td>40.758</td>
      <td>1</td>
      <td>0.910</td>
      <td>2012</td>
      <td>4</td>
      <td>21</td>
      <td>5</td>
      <td>4</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.300</td>
      <td>2010-03-09 07:51:00</td>
      <td>-73.968</td>
      <td>40.768</td>
      <td>-73.957</td>
      <td>40.784</td>
      <td>1</td>
      <td>1.361</td>
      <td>2010</td>
      <td>3</td>
      <td>9</td>
      <td>1</td>
      <td>7</td>
    </tr>
  </tbody>
</table>
</div>

### View the description of the dataset
```python
nyc.describe()
```
<div style="overflow-x:auto;">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fare_amount</th>
      <th>pickup_longitude</th>
      <th>pickup_latitude</th>
      <th>dropoff_longitude</th>
      <th>dropoff_latitude</th>
      <th>passenger_count</th>
      <th>distance</th>
      <th>year</th>
      <th>month</th>
      <th>day</th>
      <th>weekday</th>
      <th>hour</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>2914228.000</td>
      <td>2914228.000</td>
      <td>2914228.000</td>
      <td>2914228.000</td>
      <td>2914228.000</td>
      <td>2914228.000</td>
      <td>2914228.000</td>
      <td>2914228.000</td>
      <td>2914228.000</td>
      <td>2914228.000</td>
      <td>2914228.000</td>
      <td>2914228.000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>11.337</td>
      <td>-73.845</td>
      <td>40.656</td>
      <td>-73.843</td>
      <td>40.653</td>
      <td>1.685</td>
      <td>19.844</td>
      <td>2011.744</td>
      <td>6.268</td>
      <td>15.714</td>
      <td>3.041</td>
      <td>13.513</td>
    </tr>
    <tr>
      <th>std</th>
      <td>9.681</td>
      <td>8.544</td>
      <td>6.237</td>
      <td>8.362</td>
      <td>8.038</td>
      <td>1.308</td>
      <td>381.536</td>
      <td>1.864</td>
      <td>3.436</td>
      <td>8.685</td>
      <td>1.950</td>
      <td>6.513</td>
    </tr>
    <tr>
      <th>min</th>
      <td>-62.000</td>
      <td>-3426.609</td>
      <td>-3458.665</td>
      <td>-3408.430</td>
      <td>-3461.541</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>2009.000</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>0.000</td>
      <td>0.000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>6.000</td>
      <td>-73.992</td>
      <td>40.736</td>
      <td>-73.992</td>
      <td>40.735</td>
      <td>1.000</td>
      <td>0.875</td>
      <td>2010.000</td>
      <td>3.000</td>
      <td>8.000</td>
      <td>1.000</td>
      <td>9.000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>8.500</td>
      <td>-73.982</td>
      <td>40.753</td>
      <td>-73.981</td>
      <td>40.754</td>
      <td>1.000</td>
      <td>1.574</td>
      <td>2012.000</td>
      <td>6.000</td>
      <td>16.000</td>
      <td>3.000</td>
      <td>14.000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>12.500</td>
      <td>-73.968</td>
      <td>40.768</td>
      <td>-73.965</td>
      <td>40.768</td>
      <td>2.000</td>
      <td>2.864</td>
      <td>2013.000</td>
      <td>9.000</td>
      <td>23.000</td>
      <td>5.000</td>
      <td>19.000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>495.000</td>
      <td>3439.426</td>
      <td>2912.465</td>
      <td>3457.622</td>
      <td>3345.917</td>
      <td>9.000</td>
      <td>19528.468</td>
      <td>2015.000</td>
      <td>12.000</td>
      <td>31.000</td>
      <td>6.000</td>
      <td>23.000</td>
    </tr>
  </tbody>
</table>
</div>
Some things to note:
* The minimum fare amount is negative (The taxi fare initial charge is $2.5)
* Minimum and maximum longitude and latitude look unreal (New York city longitudes are around -74 and latitudes are around 41)
* Minimum passenger count is 0 and maximum passenger count is 9 (Four passengers is the limit for New York City cabs, five in minivans), so we are removing passenger count with more than 6 (taking into consideration that the additional passenger might be a child). 
* Minimum distance is 0 and the maximum distance is 19528.468km, which is quite impossible as one could travel almost half the world with that distance (Circumference of Earth is about 40,075km). Using the mean and standard deviation, we will give an approximate to the distance to be no more than 430km.

### Cleaning the data
```python
nyc = nyc[((nyc['pickup_longitude'] > -78) & (nyc['pickup_longitude'] < -70)) &
            ((nyc['dropoff_longitude'] > -78) & (nyc['dropoff_longitude'] < -70)) &
            ((nyc['pickup_latitude'] > 37) & (nyc['pickup_latitude'] < 45)) &
            ((nyc['dropoff_latitude'] > 37) & (nyc['dropoff_latitude'] < 45)) &
            ((nyc['passenger_count'] > 0) & (nyc['passenger_count'] <= 6)) &
            ((nyc['distance'] > 0) & (nyc['distance'] < 430)) &
            (nyc['fare_amount'] >= 2.5)] 
```

### View the shape of the dataset
```python
nyc.shape
```
{% highlight text %}
(2895878, 13)
{% endhighlight %} 
After cleaning, the shape of the dataset is 2,895,878 rows with 13 features.

### View the description of the dataset
```python
nyc.describe()
```
<div style="overflow-x:auto;">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fare_amount</th>
      <th>pickup_longitude</th>
      <th>pickup_latitude</th>
      <th>dropoff_longitude</th>
      <th>dropoff_latitude</th>
      <th>passenger_count</th>
      <th>distance</th>
      <th>year</th>
      <th>month</th>
      <th>day</th>
      <th>weekday</th>
      <th>hour</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>2895878.000</td>
      <td>2895878.000</td>
      <td>2895878.000</td>
      <td>2895878.000</td>
      <td>2895878.000</td>
      <td>2895878.000</td>
      <td>2895878.000</td>
      <td>2895878.000</td>
      <td>2895878.000</td>
      <td>2895878.000</td>
      <td>2895878.000</td>
      <td>2895878.000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>11.338</td>
      <td>-73.976</td>
      <td>40.751</td>
      <td>-73.975</td>
      <td>40.751</td>
      <td>1.691</td>
      <td>2.751</td>
      <td>2011.742</td>
      <td>6.270</td>
      <td>15.710</td>
      <td>3.041</td>
      <td>13.513</td>
    </tr>
    <tr>
      <th>std</th>
      <td>9.666</td>
      <td>0.041</td>
      <td>0.032</td>
      <td>0.039</td>
      <td>0.035</td>
      <td>1.306</td>
      <td>4.266</td>
      <td>1.867</td>
      <td>3.436</td>
      <td>8.685</td>
      <td>1.950</td>
      <td>6.514</td>
    </tr>
    <tr>
      <th>min</th>
      <td>2.500</td>
      <td>-77.902</td>
      <td>37.101</td>
      <td>-77.971</td>
      <td>37.102</td>
      <td>1.000</td>
      <td>0.000</td>
      <td>2009.000</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>0.000</td>
      <td>0.000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>6.000</td>
      <td>-73.992</td>
      <td>40.737</td>
      <td>-73.992</td>
      <td>40.736</td>
      <td>1.000</td>
      <td>0.874</td>
      <td>2010.000</td>
      <td>3.000</td>
      <td>8.000</td>
      <td>1.000</td>
      <td>9.000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>8.500</td>
      <td>-73.982</td>
      <td>40.753</td>
      <td>-73.981</td>
      <td>40.754</td>
      <td>1.000</td>
      <td>1.571</td>
      <td>2012.000</td>
      <td>6.000</td>
      <td>16.000</td>
      <td>3.000</td>
      <td>14.000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>12.500</td>
      <td>-73.968</td>
      <td>40.768</td>
      <td>-73.966</td>
      <td>40.768</td>
      <td>2.000</td>
      <td>2.852</td>
      <td>2013.000</td>
      <td>9.000</td>
      <td>23.000</td>
      <td>5.000</td>
      <td>19.000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>495.000</td>
      <td>-70.000</td>
      <td>44.261</td>
      <td>-70.002</td>
      <td>44.641</td>
      <td>6.000</td>
      <td>424.674</td>
      <td>2015.000</td>
      <td>12.000</td>
      <td>31.000</td>
      <td>6.000</td>
      <td>23.000</td>
    </tr>
  </tbody>
</table>
</div>
The summary statistics looks much better, however minimum distance is still at 0.

### Taking a look into minimum distance
```python
nyc.distance.min()
```
{% highlight text %}
2.9914865697067863e-05
{% endhighlight %} 
It is not exactly 0, but a number close to or converging to zero (2.9914865697067863 x 0.00001)

## 3) Exploratory data analysis
### Geographical plot of the pickup and dropoff location
```python
longitude = list(nyc.pickup_longitude) + list(nyc.dropoff_longitude)
latitude = list(nyc.pickup_latitude) + list(nyc.dropoff_latitude)
plt.figure(figsize = (20,15))
plt.plot(longitude,latitude,'.', alpha = 0.8, markersize = 0.05)
plt.xlim(-74.03, -73.875)
plt.ylim(40.65, 40.86)
plt.show()
```
<img src="{{ site.url }}{{ site.baseurl }}/images/NYC Taxi/nyc2.png" alt="">

### Geographical plot of the pickup and dropoff location (With segregation)
Blue being the pickup locations and red being the dropoff locations.
```python
longitude = list(nyc.pickup_longitude)
latitude = list(nyc.pickup_latitude)
longitude2 = list(nyc.dropoff_longitude)
latitude2 = list(nyc.dropoff_latitude)
plt.figure(figsize = (20,15))
plt.plot(longitude,latitude,'.', markersize = 0.5)
plt.plot(longitude2,latitude2,'.', alpha = 0.15, markersize = 0.25, color='r')
plt.xlim(-74.03, -73.875)
plt.ylim(40.65, 40.86)
plt.show()
```
<img src="{{ site.url }}{{ site.baseurl }}/images/NYC Taxi/nyc3.png" alt="">

### Countplot of taxi rides in daily hour periods
```python
sns.countplot(nyc['hour'], label = "Count") 
```
<img src="{{ site.url }}{{ site.baseurl }}/images/NYC Taxi/countplot.png" alt="">
<br/>
It shows that 7pm is the peak hour and 5am is the non-peak period

### Countplot of taxi rides on each weekdays (0 is for Monday)
```python
sns.countplot(x='weekday', data=nyc)
```
<img src="{{ site.url }}{{ site.baseurl }}/images/NYC Taxi/countplot2.png" alt="">
<br/>
Friday is having the highest count.

### Does number of passengers affect the fare?
```python
plt.figure(figsize=(15,7))
plt.scatter(x=nyc['passenger_count'], y=nyc['fare_amount'], s=10)
plt.xlabel('No. of Passengers')
plt.ylabel('Fare')
```
<img src="{{ site.url }}{{ site.baseurl }}/images/NYC Taxi/scatter.png" alt="">
The number of passengers does not really affect the fare.

### Does the distance affect the fare?
```python
plt.figure(figsize=(15,7))
plt.scatter(x=nyc['distance'], y=nyc['fare_amount'], s=10)
plt.xlabel('Haversine distance in kilometers')
plt.ylabel('Fare')
```
<img src="{{ site.url }}{{ site.baseurl }}/images/NYC Taxi/scatter2.png" alt="">
The travel distance does not affect the fare. But a peculiar point to note is that, at some points, as the distance increases the amount in fares does not seem to increase (It could be due to a promotional event).

### Plot of yearly distance against fare amount on a Facetgrid
Taking a further look into distance against fare plot.
```python
g = sns.FacetGrid(nyc, col="year", hue="passenger_count", col_wrap=3, height=5)
g.map(plt.scatter, "distance", "fare_amount")
g.add_legend()
```
<img src="{{ site.url }}{{ site.baseurl }}/images/NYC Taxi/facetgrid.png" alt="">
Most of the clusters of low amount of fare despite long travel distance happened between year 2009 to year 2011, with the following years having significantly lesser of these occurrences.

## 4) Modeling
### Prepare dataset for training and testing
Defining the target labels
```python
Y = nyc['fare_amount']
X = nyc.drop(columns=['fare_amount', 'pickup_datetime'])
```
Spliting the data into 8:2 for training and testing
```python
from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=5)
```

### Baseline model - Linear Regression
Using a linear regression model as a baseline model to gauge the performance and using the root mean square error metrics as evaluation.
```python
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

lr = LinearRegression()
lr.fit(X_train, Y_train)
y_pred = lr.predict(X_test)
print("Test RMSE: %.3f" % mean_squared_error(Y_test, y_pred) ** 0.5)
```
{% highlight text %}
Test RMSE: 6.218
{% endhighlight %} 
With linear regression, it gives a RMSE of $6.21.

### Random Forest
Trying the random forest ensemble method for regression.
```python
from sklearn.ensemble import RandomForestRegressor

rf = RandomForestRegressor()
rf.fit(X_train, Y_train)
y_pred = rf.predict(X_test)
print("Test RMSE: %.3f" % mean_squared_error(Y_test, y_pred) ** 0.5)
```
{% highlight text %}
Test RMSE: 3.737
{% endhighlight %} 
With random forest, the RMSE is $3.73.

## 4b) CatBoost vs Light GBM vs XGBoost
Following this article, [CatBoost vs Light GBM vs XGBoost](https://towardsdatascience.com/catboost-vs-light-gbm-vs-xgboost-5f93620723db), will be trying out a couple of other ensemble method.
### CatBoost
```python
from catboost import CatBoostRegressor

CB_model = CatBoostRegressor()
CB_model.fit(X_train, Y_train)
y_pred = CB_model.predict(X_test)
print("Test RMSE: %.3f" % mean_squared_error(Y_test, y_pred) ** 0.5)
```
{% highlight text %}
Test RMSE: 3.723
{% endhighlight %} 

### Light GBM
```python
from lightgbm import LGBMRegressor

LGBM_model = LGBMRegressor()
LGBM_model.fit(X_train, Y_train)
y_pred = LGBM_model.predict(X_test)
print("Test RMSE: %.3f" % mean_squared_error(Y_test, y_pred) ** 0.5)
```
{% highlight text %}
Test RMSE: 3.802
{% endhighlight %} 

### XGBoost
```python
from xgboost import XGBRegressor

XGB_model = XGBRegressor()
XGB_model.fit(X_train, Y_train)
y_pred = XGB_model.predict(X_test)
print("Test RMSE: %.3f" % mean_squared_error(Y_test, y_pred) ** 0.5)
```
{% highlight text %}
Test RMSE: 4.187
{% endhighlight %} 
With default settings, CatBoost seems to be peforming better out of the 3 models, with RMSE of $3.72. Which is only slightly better than the random forest model.

## 5) Conclusion
The models above could be improved by tuning some of the parameters. With CatBoost having the best outcome of these models, lets take a look at the feature importances, which can be useful for feature selection by removing zero importance features.

### Inspect the feature importances
Examine the feature importances picked up by the CatBoost model.
```python
CB_model.feature_importances_
```
{% highlight text %}
array([ 3.29479706, 10.92371113,  8.531366  , 17.77932988,  0.09902014,
       50.74653302,  5.98417673,  0.67118654,  0.09296519,  0.42370126,
        1.45321304])
{% endhighlight %} 

### Plot the feature importances on a barplot
```python
sns.barplot(y=list(nyc.loc[:, selected_predictors].columns), x=list(CB_model.feature_importances_))
```
<img src="{{ site.url }}{{ site.baseurl }}/images/NYC Taxi/barplot.png" alt="">

With the features learned by the model, "distance" seems to have a great weightage on the model. "passenger_count" and "day" is having almost zero importance, which could be considered for selection of removal.

